{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:17.382045Z",
     "start_time": "2025-06-21T13:07:17.211526Z"
    }
   },
   "cell_type": "code",
   "source": "%use coroutines\n",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:17.784570Z",
     "start_time": "2025-06-21T13:07:17.428064Z"
    }
   },
   "cell_type": "code",
   "source": "%use ktor-client",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:17.900606Z",
     "start_time": "2025-06-21T13:07:17.805533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import java.nio.file.Paths\n",
    "\n",
    "// /Users/mac/Downloads\n",
    "val prop = Paths.get(System.getProperty(\"user.home\"), \"Downloads\")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:17.999867Z",
     "start_time": "2025-06-21T13:07:17.909071Z"
    }
   },
   "cell_type": "code",
   "source": "println(prop)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mac/Downloads\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:18.272605Z",
     "start_time": "2025-06-21T13:07:18.164704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import java.io.File\n",
    "\n",
    "val file = File(\"$prop/client_secret_551260504895-km035mf33md4abv92nlo4oq18a80jhbj.apps.googleusercontent.com.json\")\n",
    "\n",
    "println(file.isFile)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:18.598596Z",
     "start_time": "2025-06-21T13:07:18.462121Z"
    }
   },
   "cell_type": "code",
   "source": "println(file.readLines())",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"installed\":{\"client_id\":\"551260504895-km035mf33md4abv92nlo4oq18a80jhbj.apps.googleusercontent.com\",\"project_id\":\"snappy-thought-423221-t8\",\"auth_uri\":\"https://accounts.google.com/o/oauth2/auth\",\"token_uri\":\"https://oauth2.googleapis.com/token\",\"auth_provider_x509_cert_url\":\"https://www.googleapis.com/oauth2/v1/certs\"}}]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:19.233845Z",
     "start_time": "2025-06-21T13:07:19.073607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// JetDrive props\n",
    "val uploadUrl = \"http://localhost:8080/upload\"\n",
    "val initiateUrl = \"$uploadUrl/initiate\"\n",
    "val uploadChunkUrl: (String) -> String = { \"$uploadUrl/$it\" }\n",
    "val completeUrl: (String) -> String = { \"$uploadUrl/$it/complete\" }\n",
    "val statusUrl: (String) -> String = { \"$uploadUrl/status/$it\" }"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:19.557090Z",
     "start_time": "2025-06-21T13:07:19.472863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// JetDrive auth token\n",
    "val access = \"eyJhbGciOiJIUzI1NiJ9.eyJ0eXBlIjoiYWNjZXNzIiwic3ViIjoiaW5mb0BhYmMuY29tIiwiaWF0IjoxNzUwNTA1MjkxLCJleHAiOjE3NTA1OTE2OTF9.CIE72XtdfVIFubzVRv7Ui8MSQ6-lnhYAwa2_uDAM2v0\"\n",
    "\n",
    "val refresh = \"eyJhbGciOiJIUzI1NiJ9.eyJ0eXBlIjoicmVmcmVzaCIsInN1YiI6ImluZm9AYWJjLmNvbSIsImlhdCI6MTc1MDQxNzg2MCwiZXhwIjoxNzUzMDA5ODYwfQ.ytX-5ofPoWut1cs6Pv2waCQ5_UOjfkH6k4pavBffRKI\""
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:20.304959Z",
     "start_time": "2025-06-21T13:07:19.917871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import io.ktor.client.*\n",
    "import io.ktor.client.engine.cio.*\n",
    "import io.ktor.client.plugins.auth.*\n",
    "import io.ktor.client.plugins.auth.providers.*\n",
    "import io.ktor.client.plugins.contentnegotiation.*\n",
    "import io.ktor.serialization.kotlinx.json.*\n",
    "\n",
    "val client = HttpClient(CIO) {\n",
    "    install(Auth) {\n",
    "        bearer {\n",
    "            loadTokens {\n",
    "                BearerTokens(\n",
    "                    accessToken = access, refreshToken = refresh)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    install(ContentNegotiation) {\n",
    "        json(Json {\n",
    "            prettyPrint = true\n",
    "            isLenient = true\n",
    "        })\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:21.497768Z",
     "start_time": "2025-06-21T13:07:20.350705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@Serializable\n",
    "data class UploadInitiateRequest(\n",
    "    val fileName: String, val fileSize: Long,\n",
    "    val parentId: String? = null, val hasThumbnail: Boolean = false\n",
    ")\n",
    "@Serializable\n",
    "data class UploadInitiateResponse(val uploadId: String, val chunkSize: Int)\n",
    "@Serializable\n",
    "data class UploadProgressResponse(val uploadedChunks: Set<Long>, val totalBytes: Long, val uploadedBytes: Long, val chunkSize: Int)\n",
    "\n",
    "@Serializable\n",
    "data class S3UploadProgressResponse(\n",
    "    val uploadedChunks: List<Int>, val totalBytes: Long,\n",
    "    val uploadedBytes: Long, val chunkSize: Int, val uploadStatus: String\n",
    ") {\n",
    "    val missingChunks: List<Int>\n",
    "        get() = uploadedChunks\n",
    "}\n",
    "\n",
    "@Serializable\n",
    "data class FileNodeDTO (\n",
    "    val id: String? = null, val name: String? = null, val type: String? = null, val size: Long? = null,\n",
    "    val parentId: String? = null, val hasThumbnail: Boolean = false, val mimeType: String? = null,\n",
    "    val createdAt: String? = null, val updatedAt: String? = null,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:21.712768Z",
     "start_time": "2025-06-21T13:07:21.607475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "//val file = File(\"$prop/exc.png\")\n",
    "val file = File(\"$prop/GET THE GIRL!!! - The Office - 8x19 - Group Reaction.mp4\")\n",
    "//val file = File(\"$prop/Single-Threaded Coroutines in Kotlin.mp4\")\n",
    "println(file.isFile)\n",
    "println(file.length())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "56405497\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:22.217559Z",
     "start_time": "2025-06-21T13:07:21.974248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fun calculateProgress(response: UploadProgressResponse): Int {\n",
    "    val percent = (response.uploadedBytes.toDouble() / response.totalBytes .toDouble()) * 100\n",
    "    return percent.coerceAtMost(100.0).toInt()\n",
    "}\n",
    "\n",
    "fun calculateProgress(response: S3UploadProgressResponse): Int {\n",
    "    val percent = (response.uploadedBytes.toDouble() / response.totalBytes .toDouble()) * 100\n",
    "    return percent.coerceAtMost(100.0).toInt()\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:23.258484Z",
     "start_time": "2025-06-21T13:07:22.451761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import io.ktor.client.call.*\n",
    "import io.ktor.client.request.*\n",
    "import io.ktor.client.statement.*\n",
    "import io.ktor.http.*\n",
    "\n",
    "suspend fun startS3Upload(file: File, chunkSize: Int, uploadId: String, onChunkUpload: (S3UploadProgressResponse) -> Unit, onComplete: (FileNodeDTO) -> Unit) {\n",
    "    val inputStream = file.inputStream().buffered()\n",
    "    var start = 0L\n",
    "    val total = file.length()\n",
    "    var chunkIndex = 0\n",
    "\n",
    "    while (start < total) {\n",
    "        val buffer = ByteArray(chunkSize)\n",
    "        val read = inputStream.read(buffer)\n",
    "        if (read == -1) break\n",
    "\n",
    "        val end = start + read - 1\n",
    "        val actualChunk = buffer.copyOf(read)\n",
    "\n",
    "        val rangeHeader = \"bytes $start-$end/$total\"\n",
    "        val response = client.put(uploadChunkUrl(uploadId)) {\n",
    "            header(HttpHeaders.ContentRange, rangeHeader)\n",
    "            header(HttpHeaders.ContentType, ContentType.Application.OctetStream)\n",
    "            setBody(actualChunk)\n",
    "        }\n",
    "\n",
    "        if (!response.status.isSuccess()) {\n",
    "            println(\"Failed on chunk $chunkIndex: ${response.status}\")\n",
    "            return\n",
    "        }\n",
    "\n",
    "        if (response.status.isSuccess()) {\n",
    "            val progress: S3UploadProgressResponse = response.body()\n",
    "            onChunkUpload(progress)\n",
    "        }\n",
    "\n",
    "        start = end + 1\n",
    "        chunkIndex++\n",
    "    }\n",
    "\n",
    "    println(\"Finalizing upload...\")\n",
    "    val completeResponse: FileNodeDTO = client.post(completeUrl(uploadId)).body()\n",
    "    onComplete(completeResponse)\n",
    "\n",
    "    client.close()\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:24.226327Z",
     "start_time": "2025-06-21T13:07:23.340971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// Resumable upload\n",
    "suspend fun startS3PartialUpload(file: File, chunkSize: Int, uploadId: String, onChunkUpload: (S3UploadProgressResponse) -> Unit, onComplete: (FileNodeDTO) -> Unit) {\n",
    "    val inputStream = file.inputStream().buffered()\n",
    "    var start = 0L\n",
    "    val total = file.length()\n",
    "    var chunkIndex = 0\n",
    "\n",
    "    while (start < total) {\n",
    "        val buffer = ByteArray(chunkSize)\n",
    "        val read = inputStream.read(buffer)\n",
    "        if (read == -1) break\n",
    "\n",
    "        val end = start + read - 1\n",
    "        val actualChunk = buffer.copyOf(read)\n",
    "\n",
    "        if (chunkIndex < 2 || chunkIndex % 2 == 0) {\n",
    "\n",
    "            val rangeHeader = \"bytes $start-$end/$total\"\n",
    "            val response: HttpResponse = client.put(uploadChunkUrl(uploadId)) {\n",
    "                header(HttpHeaders.ContentRange, rangeHeader)\n",
    "                header(HttpHeaders.ContentType, ContentType.Application.OctetStream)\n",
    "                setBody(actualChunk)\n",
    "            }\n",
    "\n",
    "            if (!response.status.isSuccess()) {\n",
    "                println(\"Failed on chunk $chunkIndex: ${response.status}\")\n",
    "                return\n",
    "            }\n",
    "\n",
    "            if (response.status.isSuccess()) {\n",
    "                val progress: S3UploadProgressResponse = response.body()\n",
    "                onChunkUpload(progress)\n",
    "            }\n",
    "\n",
    "        }\n",
    "        start = end + 1\n",
    "        chunkIndex++\n",
    "    }\n",
    "\n",
    "    println(\"Finalizing upload...\")\n",
    "    val completeResponse = client.post(completeUrl(uploadId))\n",
    "\n",
    "    if (!completeResponse.status.isSuccess()) {\n",
    "        println(\"File uplaod failed\")\n",
    "        return\n",
    "    }\n",
    "\n",
    "    if (completeResponse.status.isSuccess()) {\n",
    "        val response: FileNodeDTO = completeResponse.body()\n",
    "        onComplete(response)\n",
    "    }\n",
    "\n",
    "    client.close()\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:25.142655Z",
     "start_time": "2025-06-21T13:07:24.557440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// Resumable upload\n",
    "suspend fun startPartialUpload(file: File, chunkSize: Int, uploadId: String, block: (String, HttpResponse) -> Unit) {\n",
    "    val inputStream = file.inputStream().buffered()\n",
    "    var start = 0L\n",
    "    val total = file.length()\n",
    "    var chunkIndex = 0\n",
    "\n",
    "    while (start < total) {\n",
    "        val buffer = ByteArray(chunkSize)\n",
    "        val read = inputStream.read(buffer)\n",
    "        if (read == -1) break\n",
    "\n",
    "        val end = start + read - 1\n",
    "        val actualChunk = buffer.copyOf(read)\n",
    "\n",
    "        if (chunkIndex < 2 || chunkIndex % 2 == 0) {\n",
    "\n",
    "            val rangeHeader = \"bytes $start-$end/$total\"\n",
    "            val response: HttpResponse = client.put(uploadChunkUrl(uploadId)) {\n",
    "                header(HttpHeaders.ContentRange, rangeHeader)\n",
    "                header(HttpHeaders.ContentType, ContentType.Application.OctetStream)\n",
    "                setBody(actualChunk)\n",
    "            }\n",
    "\n",
    "            block(chunkIndex.toString(),response)\n",
    "\n",
    "            if (!response.status.isSuccess()) {\n",
    "                println(\"Failed on chunk $chunkIndex: ${response.status}\")\n",
    "                return\n",
    "            }\n",
    "\n",
    "        }\n",
    "        start = end + 1\n",
    "        chunkIndex++\n",
    "    }\n",
    "\n",
    "    println(\"Finalizing upload...\")\n",
    "    val completeResponse = client.post(completeUrl(uploadId))\n",
    "\n",
    "    println(\"Upload complete: ${completeResponse.status}\")\n",
    "    client.close()\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:26.558256Z",
     "start_time": "2025-06-21T13:07:25.431388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "suspend fun resumeS3Upload(\n",
    "    file: File,\n",
    "    chunkSize: Int,\n",
    "    uploadId: String,\n",
    "    missingChunks: Set<Int>, // direct from backend\n",
    "    onChunkUpload: (S3UploadProgressResponse) -> Unit,\n",
    "    onComplete: (FileNodeDTO) -> Unit\n",
    ") {\n",
    "    val total = file.length()\n",
    "    val totalChunks = ((total + chunkSize - 1) / chunkSize).toInt()\n",
    "\n",
    "    val inputStream = file.inputStream().buffered()\n",
    "\n",
    "    for (chunkIndex in 0 until totalChunks) {\n",
    "        val start = chunkIndex * chunkSize.toLong()\n",
    "        val end = minOf(start + chunkSize, total) - 1\n",
    "        val bufferSize = (end - start + 1).toInt()\n",
    "\n",
    "        if (!missingChunks.contains(chunkIndex)) {\n",
    "            println(\"Skipping already uploaded chunk $chunkIndex at offset $start\")\n",
    "            inputStream.skip(bufferSize.toLong())\n",
    "            continue\n",
    "        }\n",
    "\n",
    "        val buffer = ByteArray(bufferSize)\n",
    "        val read = inputStream.read(buffer)\n",
    "        if (read == -1) break\n",
    "\n",
    "        val actualChunk = buffer.copyOf(read)\n",
    "        val rangeHeader = \"bytes $start-$end/$total\"\n",
    "        println(\"Uploading chunk $chunkIndex at offset $start\")\n",
    "        val response: HttpResponse = client.put(uploadChunkUrl(uploadId)) {\n",
    "            header(HttpHeaders.ContentRange, rangeHeader)\n",
    "            header(HttpHeaders.ContentType, ContentType.Application.OctetStream)\n",
    "            setBody(actualChunk)\n",
    "        }\n",
    "\n",
    "        if (!response.status.isSuccess()) {\n",
    "            println(\"Failed on chunk $chunkIndex: ${response.status}\")\n",
    "            return\n",
    "        }\n",
    "\n",
    "        if (response.status.isSuccess()) {\n",
    "            val progress: S3UploadProgressResponse = response.body()\n",
    "            onChunkUpload(progress)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    println(\"Finalizing upload...\")\n",
    "    val completeResponse = client.post(completeUrl(uploadId))\n",
    "\n",
    "    if (completeResponse.status == HttpStatusCode.PartialContent) {\n",
    "        println(\"message: ${completeResponse.bodyAsText()}\")\n",
    "        return\n",
    "    }\n",
    "\n",
    "    if (!completeResponse.status.isSuccess()) {\n",
    "        println(\"File uplaod failed\")\n",
    "        return\n",
    "    }\n",
    "\n",
    "    if (completeResponse.status.isSuccess()) {\n",
    "        println(\"completeResponse body: ${completeResponse.bodyAsText()}\")\n",
    "        val response: FileNodeDTO = completeResponse.body()\n",
    "        onComplete(response)\n",
    "    }\n",
    "    client.close()\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:27.543312Z",
     "start_time": "2025-06-21T13:07:26.800584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// resumeS3Upload V2\n",
    "suspend fun resumeS3Upload2(\n",
    "    file: File,\n",
    "    chunkSize: Int,\n",
    "    uploadId: String,\n",
    "    uploadedChunkIndexes: Set<Int>,\n",
    "    onChunkUpload: (S3UploadProgressResponse) -> Unit,\n",
    "    onComplete: (FileNodeDTO) -> Unit\n",
    ") {\n",
    "    val inputStream = file.inputStream().buffered()\n",
    "    val total = file.length()\n",
    "    var start = 0L\n",
    "    var chunkIndex = 0\n",
    "\n",
    "    while (start < total) {\n",
    "        val buffer = ByteArray(chunkSize)\n",
    "        val read = inputStream.read(buffer)\n",
    "        if (read == -1) break\n",
    "\n",
    "        // Check if this chunk has already been uploaded\n",
    "        if (uploadedChunkIndexes.contains(chunkIndex)) {\n",
    "            println(\"Skipping chunk $chunkIndex at offset $start\")\n",
    "            start += read\n",
    "            chunkIndex++\n",
    "            continue\n",
    "        }\n",
    "\n",
    "        val end = start + read - 1\n",
    "        val actualChunk = buffer.copyOf(read)\n",
    "\n",
    "        val rangeHeader = \"bytes $start-$end/$total\"\n",
    "        println(\"Uploading chunk $chunkIndex at offset $start\")\n",
    "        val response: HttpResponse = client.put(uploadChunkUrl(uploadId)) {\n",
    "            header(HttpHeaders.ContentRange, rangeHeader)\n",
    "            header(HttpHeaders.ContentType, ContentType.Application.OctetStream)\n",
    "            setBody(actualChunk)\n",
    "        }\n",
    "\n",
    "        if (!response.status.isSuccess()) {\n",
    "            println(\"Failed on chunk $chunkIndex: ${response.status}\")\n",
    "            return\n",
    "        }\n",
    "\n",
    "        if (response.status.isSuccess()) {\n",
    "            val progress: S3UploadProgressResponse = response.body()\n",
    "            onChunkUpload(progress)\n",
    "        }\n",
    "\n",
    "        start = end + 1\n",
    "        chunkIndex++\n",
    "    }\n",
    "\n",
    "    println(\"Finalizing upload...\")\n",
    "    val completeResponse = client.post(completeUrl(uploadId))\n",
    "    println(\"Complete status: $completeResponse\")\n",
    "\n",
    "    if (completeResponse.status == HttpStatusCode.PartialContent) {\n",
    "        println(\"message: ${completeResponse.bodyAsText()}\")\n",
    "        return\n",
    "    }\n",
    "\n",
    "    if (!completeResponse.status.isSuccess()) {\n",
    "        println(\"File uplaod failed\")\n",
    "        return\n",
    "    }\n",
    "\n",
    "    if (completeResponse.status.isSuccess()) {\n",
    "        val response: FileNodeDTO = completeResponse.body()\n",
    "        onComplete(response)\n",
    "    }\n",
    "\n",
    "    client.close()\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T13:07:28.209319Z",
     "start_time": "2025-06-21T13:07:27.811505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "suspend fun resumeUpload(\n",
    "    file: File,\n",
    "    chunkSize: Int,\n",
    "    uploadId: String,\n",
    "    uploadedChunkOffsets: Set<Long>, // get this from the backend\n",
    "    block: (String, HttpResponse) -> Unit\n",
    ") {\n",
    "    val inputStream = file.inputStream().buffered()\n",
    "    val total = file.length()\n",
    "    var start = 0L\n",
    "    var chunkIndex = 0\n",
    "\n",
    "    while (start < total) {\n",
    "        val buffer = ByteArray(chunkSize)\n",
    "        val read = inputStream.read(buffer)\n",
    "        if (read == -1) break\n",
    "\n",
    "        // Check if this chunk has already been uploaded\n",
    "        if (uploadedChunkOffsets.contains(start)) {\n",
    "            println(\"Skipping chunk $chunkIndex at offset $start\")\n",
    "            start += read\n",
    "            chunkIndex++\n",
    "            continue\n",
    "        }\n",
    "\n",
    "        val end = start + read - 1\n",
    "        val actualChunk = buffer.copyOf(read)\n",
    "\n",
    "        val rangeHeader = \"bytes $start-$end/$total\"\n",
    "        val response: HttpResponse = client.put(uploadChunkUrl(uploadId)) {\n",
    "            header(HttpHeaders.ContentRange, rangeHeader)\n",
    "            header(HttpHeaders.ContentType, ContentType.Application.OctetStream)\n",
    "            setBody(actualChunk)\n",
    "        }\n",
    "\n",
    "        block(chunkIndex.toString(), response)\n",
    "\n",
    "        if (!response.status.isSuccess()) {\n",
    "            println(\"Failed on chunk $chunkIndex (range: $start-$end): ${response.status}\")\n",
    "            return\n",
    "        }\n",
    "\n",
    "        start = end + 1\n",
    "        chunkIndex++\n",
    "    }\n",
    "\n",
    "    println(\"Finalizing upload...\")\n",
    "    val completeResponse = client.post(completeUrl(uploadId))\n",
    "    println(\"Upload complete: ${completeResponse.status}\")\n",
    "    client.close()\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-21T13:07:28.710086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import io.ktor.client.call.*\n",
    "import io.ktor.client.request.*\n",
    "import io.ktor.http.*\n",
    "\n",
    "/*\n",
    "// ------------------------------- S3Complete ---------------------\n",
    "runBlocking {\n",
    "    try {\n",
    "        val initiateResponse: UploadInitiateResponse = client.post(initiateUrl) {\n",
    "            contentType(ContentType.Application.Json)\n",
    "            setBody(UploadInitiateRequest(file.name, file.length(), null))\n",
    "        }.body()\n",
    "        println(uploadChunkUrl(initiateResponse.uploadId))\n",
    "        println(completeUrl(\"xb\"))\n",
    "        //println(\"Response: ${initiateResponse}\")\n",
    "\n",
    "        startS3Upload(file = file, chunkSize = initiateResponse.chunkSize, uploadId = initiateResponse.uploadId, onChunkUpload = { progress ->\n",
    "            val calculateProgress = calculateProgress(progress)\n",
    "            println(\"Progress: $calculateProgress%\")\n",
    "        }) { fileNode ->\n",
    "            println(\"Upload sucessful: $fileNode\")\n",
    "        }\n",
    "\n",
    "    } catch (ex: Exception) {\n",
    "        println(\"Error: $ex\")\n",
    "    } finally {\n",
    "        System.exit(1)\n",
    "    }\n",
    "}\n",
    "*/\n",
    "\n",
    "/*\n",
    "// ------------------------------------ S3Partial ------------------------------------\n",
    "runBlocking {\n",
    "    try {\n",
    "        val initiateResponse: UploadInitiateResponse = client.post(initiateUrl) {\n",
    "            contentType(ContentType.Application.Json)\n",
    "            setBody(UploadInitiateRequest(file.name, file.length()))\n",
    "        }.body()\n",
    "        println(uploadChunkUrl(initiateResponse.uploadId))\n",
    "\n",
    "        startS3PartialUpload(file = file, chunkSize = initiateResponse.chunkSize, uploadId = initiateResponse.uploadId, onChunkUpload = { progress ->\n",
    "            val calculateProgress = calculateProgress(progress)\n",
    "            println(\"Progress: $calculateProgress%\")\n",
    "        }) { fileNode ->\n",
    "            println(\"Upload sucessful: $fileNode\")\n",
    "        }\n",
    "\n",
    "    } catch (ex: Exception) {\n",
    "        println(\"Error: $ex\")\n",
    "    } finally {\n",
    "        System.exit(1)\n",
    "    }\n",
    "}\n",
    "*/\n",
    "\n",
    "///*\n",
    "// ------------------------------------ S3Retry ------------------------------------\n",
    "runBlocking {\n",
    "    try {\n",
    "        val uploadId = \"2528b45a-e016-49bd-9012-e44f969f8294\"\n",
    "        val statusResponse: S3UploadProgressResponse = client.get(statusUrl(uploadId)).body()\n",
    "        println(\"statusResponse uploadedChunks: ${statusResponse.missingChunks}\")\n",
    "        println(\"statusResponse totalBytes: ${statusResponse.totalBytes}\")\n",
    "\n",
    "        resumeS3Upload(file = file, chunkSize = statusResponse.chunkSize,\n",
    "            uploadId = uploadId,\n",
    "            missingChunks = statusResponse.missingChunks.toSet(),\n",
    "            onChunkUpload = { progress ->\n",
    "                val calculateProgress = calculateProgress(progress)\n",
    "                println(\"Progress: $calculateProgress%\")\n",
    "            }\n",
    "        ) { fileNode ->\n",
    "            println(\"Upload sucessful: $fileNode\")\n",
    "        }\n",
    "\n",
    "    } catch (ex: Exception) {\n",
    "        println(\"Error: $ex\")\n",
    "        throw ex\n",
    "    } finally {\n",
    "        System.exit(1)\n",
    "    }\n",
    "}\n",
    "//*/\n",
    "\n",
    "\n",
    "/*\n",
    "// ------------------------------------ Partial ------------------------------------\n",
    "runBlocking {\n",
    "    try {\n",
    "        val initiateResponse: UploadInitiateResponse = client.post(initiateUrl) {\n",
    "            contentType(ContentType.Application.Json)\n",
    "            setBody(UploadInitiateRequest(file.name, file.length()))\n",
    "        }.body()\n",
    "        println(uploadChunkUrl(initiateResponse.uploadId))\n",
    "        println(completeUrl(\"xb\"))\n",
    "        //println(\"Response: ${initiateResponse}\")\n",
    "\n",
    "        startPartialUpload(file = file, chunkSize = initiateResponse.chunkSize, uploadId = initiateResponse.uploadId) { chunk, response ->\n",
    "            if (!response.status.isSuccess()) {\n",
    "                println(\"Failed on chunk $chunk: ${response.status}\")\n",
    "            } else println(\"Uploaded chunck $chunk\")\n",
    "        }\n",
    "\n",
    "    } catch (ex: Exception) {\n",
    "        println(\"Error: $ex\")\n",
    "    } finally {\n",
    "        System.exit(1)\n",
    "    }\n",
    "}\n",
    "*/\n",
    "\n",
    "/*\n",
    "// ------------------------------------ Retry ------------------------------------\n",
    "runBlocking {\n",
    "    try {\n",
    "        val uploadId = \"996cbb9b-0acb-4eac-8aef-9f0c0b541a7f\"\n",
    "        val statusResponse: UploadProgressResponse = client.get(statusUrl(uploadId)).body()\n",
    "        println(\"statusResponse uploadedChunks: ${statusResponse.uploadedChunks}\")\n",
    "        println(\"statusResponse totalBytes: ${statusResponse.getTotalBytes}\")\n",
    "\n",
    "        resumeUpload(file = file, chunkSize = 1048576, uploadId = uploadId, uploadedChunkOffsets = statusResponse.uploadedChunks) { chunk, response ->\n",
    "            if (!response.status.isSuccess()) {\n",
    "                println(\"Failed on chunk $chunk: ${response.status}\")\n",
    "            } else println(\"Uploaded chunck $chunk\")\n",
    "        }\n",
    "\n",
    "    } catch (ex: Exception) {\n",
    "        println(\"Error: $ex\")\n",
    "    } finally {\n",
    "        System.exit(1)\n",
    "    }\n",
    "}\n",
    "*/\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statusResponse uploadedChunks: [1]\n",
      "statusResponse totalBytes: 56405497\n",
      "Skipping already uploaded chunk 0 at offset 0\n",
      "Uploading chunk 1 at offset 1048576\n",
      "Progress: 3%\n",
      "Skipping already uploaded chunk 2 at offset 2097152\n",
      "Skipping already uploaded chunk 3 at offset 3145728\n",
      "Skipping already uploaded chunk 4 at offset 4194304\n",
      "Skipping already uploaded chunk 5 at offset 5242880\n",
      "Skipping already uploaded chunk 6 at offset 6291456\n",
      "Skipping already uploaded chunk 7 at offset 7340032\n",
      "Skipping already uploaded chunk 8 at offset 8388608\n",
      "Skipping already uploaded chunk 9 at offset 9437184\n",
      "Skipping already uploaded chunk 10 at offset 10485760\n",
      "Skipping already uploaded chunk 11 at offset 11534336\n",
      "Skipping already uploaded chunk 12 at offset 12582912\n",
      "Skipping already uploaded chunk 13 at offset 13631488\n",
      "Skipping already uploaded chunk 14 at offset 14680064\n",
      "Skipping already uploaded chunk 15 at offset 15728640\n",
      "Skipping already uploaded chunk 16 at offset 16777216\n",
      "Skipping already uploaded chunk 17 at offset 17825792\n",
      "Skipping already uploaded chunk 18 at offset 18874368\n",
      "Skipping already uploaded chunk 19 at offset 19922944\n",
      "Skipping already uploaded chunk 20 at offset 20971520\n",
      "Skipping already uploaded chunk 21 at offset 22020096\n",
      "Skipping already uploaded chunk 22 at offset 23068672\n",
      "Skipping already uploaded chunk 23 at offset 24117248\n",
      "Skipping already uploaded chunk 24 at offset 25165824\n",
      "Skipping already uploaded chunk 25 at offset 26214400\n",
      "Skipping already uploaded chunk 26 at offset 27262976\n",
      "Skipping already uploaded chunk 27 at offset 28311552\n",
      "Skipping already uploaded chunk 28 at offset 29360128\n",
      "Skipping already uploaded chunk 29 at offset 30408704\n",
      "Skipping already uploaded chunk 30 at offset 31457280\n",
      "Skipping already uploaded chunk 31 at offset 32505856\n",
      "Skipping already uploaded chunk 32 at offset 33554432\n",
      "Skipping already uploaded chunk 33 at offset 34603008\n",
      "Skipping already uploaded chunk 34 at offset 35651584\n",
      "Skipping already uploaded chunk 35 at offset 36700160\n",
      "Skipping already uploaded chunk 36 at offset 37748736\n",
      "Skipping already uploaded chunk 37 at offset 38797312\n",
      "Skipping already uploaded chunk 38 at offset 39845888\n",
      "Skipping already uploaded chunk 39 at offset 40894464\n",
      "Skipping already uploaded chunk 40 at offset 41943040\n",
      "Skipping already uploaded chunk 41 at offset 42991616\n",
      "Skipping already uploaded chunk 42 at offset 44040192\n",
      "Skipping already uploaded chunk 43 at offset 45088768\n",
      "Skipping already uploaded chunk 44 at offset 46137344\n",
      "Skipping already uploaded chunk 45 at offset 47185920\n",
      "Skipping already uploaded chunk 46 at offset 48234496\n",
      "Skipping already uploaded chunk 47 at offset 49283072\n",
      "Skipping already uploaded chunk 48 at offset 50331648\n",
      "Skipping already uploaded chunk 49 at offset 51380224\n",
      "Skipping already uploaded chunk 50 at offset 52428800\n",
      "Skipping already uploaded chunk 51 at offset 53477376\n",
      "Skipping already uploaded chunk 52 at offset 54525952\n",
      "Skipping already uploaded chunk 53 at offset 55574528\n",
      "Finalizing upload...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
